{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How to generate a AUC ROC curve"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ROC: Receiver Operating Characteristic graphs allow us to determine optimal precision-recall tradeoff balances specific to the problem you are looking to solve."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You've already seen the True Positive Rate before, it's another name for recall! As a reminder, it's the ratio of the true positive predictions compared to all values that are actually positive. Mathematically, it is represented by:\n",
    "\n",
    "TPR=TPTP+FN\n",
    " \n",
    "False positive rate is the ratio of the false positive predictions compared to all values that are actually negative. Mathematically, it's represented as:\n",
    "\n",
    "FPR=FPFP+TN\n",
    " \n",
    "When training a classifier, the best performing models will have an ROC curve that hugs the upper lem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The ROC curve\n",
    "\n",
    "The Receiver Operator Characteristic curve (ROC curve) illustrates the true positive rate against the false positive rate of our classifier.\n",
    "\n",
    "You've already seen the True Positive Rate before, it's another name for **recall**! As a reminder, it's the ratio of the true positive predictions compared to all values that are actually positive. Mathematically, it is represented by:\n",
    "\n",
    "$$ \\text{TPR} = \\frac{\\text{TP}}{\\text{TP}+\\text{FN}} $$\n",
    "\n",
    "False positive rate is the ratio of the false positive predictions compared to all values that are actually negative. Mathematically, it's represented as:\n",
    "\n",
    "$$ \\text{FPR} = \\frac{\\text{FP}}{\\text{FP}+\\text{TN}}$$\n",
    "\n",
    "When training a classifier, the best performing models will have an ROC curve that hugs the upper left corner of the graph. A classifier with 50-50 accuracy is deemed 'worthless'; this is no better than random guessing, as in the case of a coin flip.\n",
    "\n",
    "<img src=\"./images/Image_144_ROC.png\" width=\"400\">\n",
    "\n",
    "The ROC curve gives us a graph of the tradeoff between this false positive and true positive rate. The AUC, or area under the curve, gives us a singular metric to compare these. An AUC of 1 being a perfect classifier, and an AUC of 0.5 being that which has a precision of 50%."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "\n",
    "# Load the data\n",
    "df = pd.read_csv('heart.csv')\n",
    "\n",
    "# Define appropriate X and y\n",
    "y = df['target']\n",
    "X = df.drop(columns='target', axis=1)\n",
    "\n",
    "# Normalize the Data\n",
    "X = X.apply(lambda x : (x - x.min()) /(x.max() - x.min()),axis=0)\n",
    "\n",
    "# Split the data into train and test sets.\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)\n",
    "\n",
    "# Fit a model\n",
    "logreg = LogisticRegression(fit_intercept=False, C=1e12, solver='liblinear')\n",
    "logreg.fit(X_train, y_train)\n",
    "print(logreg) # Preview model params\n",
    "\n",
    "# Predict\n",
    "y_hat_test = logreg.predict(X_test)\n",
    "\n",
    "# Data preview\n",
    "print(\"\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('AUC: {}'.format(auc(fpr, tpr)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "# Seaborn's beautiful styling\n",
    "sns.set_style('darkgrid', {'axes.facecolor': '0.9'})\n",
    "\n",
    "print('AUC: {}'.format(auc(fpr, tpr)))\n",
    "plt.figure(figsize=(10, 8))\n",
    "lw = 2\n",
    "plt.plot(fpr, tpr, color='darkorange',\n",
    "         lw=lw, label='ROC curve')\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.yticks([i/20.0 for i in range(21)])\n",
    "plt.xticks([i/20.0 for i in range(21)])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver operating characteristic (ROC) Curve')\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
